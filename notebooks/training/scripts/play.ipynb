{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add repo path to the system path\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "repo_path= Path.cwd().resolve()\n",
    "while '.gitignore' not in os.listdir(repo_path): # while not in the root of the repo\n",
    "    repo_path = repo_path.parent #go up one level\n",
    "sys.path.insert(0,str(repo_path)) if str(repo_path) not in sys.path else None\n",
    "\n",
    "# #sklearnex\n",
    "# from sklearnex import patch_sklearn\n",
    "# patch_sklearn()\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# StratifiedKFold\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                            recall_score,\n",
    "                            precision_score,\n",
    "                            f1_score,\n",
    "                            roc_auc_score,\n",
    "                            roc_curve,\n",
    "                            matthews_corrcoef,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import cv2 as cv\n",
    "from radiomics import featureextractor\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# RandomizedSearchCV\n",
    "#Import paths and patients classes\n",
    "from notebooks.info import path_label, patient\n",
    "import notebooks.utils as utils\n",
    "\n",
    "def get_features(show=False):\n",
    "    \"\"\"returns available features for the uncertainty scheme\n",
    "\n",
    "    Args:\n",
    "        show (bool, optional): if information about the excluded features and nxp size should be given. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: features loaded\n",
    "    \"\"\"\n",
    "    budget_path = repo_path/ 'data' / 'budget' / 'budget_ROI_and_rad.csv'\n",
    "    excluded, _ = utils.get_ex_included(budget_path) # get excluded features due to their budget value\n",
    "    features = pd.read_csv(repo_path / 'data' / 'features' / f'feat_vector.csv', index_col=0)\n",
    "    # remove features in excluded list\n",
    "    features = features.drop(excluded, axis=1)\n",
    "    if show:\n",
    "        print(f'The features removed are {excluded.values} beacuse their budget value is greater than 1')\n",
    "        n = features.shape[0] # number of patients\n",
    "        p = features.shape[1] # number of features\n",
    "        print(f'The number of patients (n) is: {n}\\nThe number of features (p) is: {p}')\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features removed are ['glcm_ClusterShade'] beacuse their budget value is greater than 1\n",
      "The number of patients (n) is: 33\n",
      "The number of features (p) is: 101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# experiment HP\n",
    "label = 'RP' # receptor type (RP, RE, ki67)\n",
    "\n",
    "# get pat info and features\n",
    "info = path_label()\n",
    "features = get_features(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00068904, 0.00056375, 0.00093332, 0.00063497, 0.0008432 ,\n",
       "       0.0003523 , 0.00084584, 0.00053956, 0.0005096 , 0.00049393,\n",
       "       0.00066288, 0.00086068, 0.00082091, 0.00043792, 0.00058226,\n",
       "       0.00055402, 0.0005179 , 0.00064137, 0.00079032, 0.00084167,\n",
       "       0.00082123, 0.00082932, 0.00063231, 0.00050516, 0.00073148,\n",
       "       0.0006744 , 0.00057246, 0.0004898 , 0.00031879, 0.00059651,\n",
       "       0.00044299, 0.00097484, 0.00054212])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(info.labels_list(label))\n",
    "x = np.asarray(features)\n",
    "x[:,-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avfu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
