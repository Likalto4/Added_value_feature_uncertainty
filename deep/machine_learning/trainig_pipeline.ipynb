{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add repo path to the system path\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "repo_path= Path.cwd().resolve()\n",
    "while '.gitignore' not in os.listdir(repo_path): # while not in the root of the repo\n",
    "    repo_path = repo_path.parent #go up one level\n",
    "sys.path.insert(0,str(repo_path)) if str(repo_path) not in sys.path else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset_INCan, patient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# normalize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# simple SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# use leave one out cross validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "# confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data to have zero mean and unit variance (Standard Scaling).\n",
    "- We may try other normalization?\n",
    "- In practice SVM and most of the other algorithms work better if the features are normalized like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get X values\n",
    "# features = pd.read_csv(repo_path / 'data/deep/features/features_1024/V_1_features.csv')\n",
    "# # remove the first column\n",
    "# features = features.iloc[:,1:]\n",
    "# # get y values\n",
    "# labels = dataset_INCan().labels_list(receptor='RE')\n",
    "# # labels to df\n",
    "# labels = pd.DataFrame(labels, columns=['label'])\n",
    "# # print label distribution porcentage\n",
    "# print(labels['label'].value_counts(normalize=True).values[0].round(3))\n",
    "\n",
    "# # create the scaler\n",
    "# scaler = StandardScaler()\n",
    "# # fit the scaler\n",
    "# scaler.fit(features)\n",
    "# # transform the features\n",
    "# features = pd.DataFrame(scaler.transform(features))\n",
    "\n",
    "# # create the classifier\n",
    "# clf = SVC(kernel='linear', C=0.1, gamma=0.1, probability=True)\n",
    "# # create the cross validation\n",
    "# loo = LeaveOneOut()\n",
    "# # get the number of samples\n",
    "# n_samples = len(features)\n",
    "# # create the predictions list\n",
    "# predictions = []\n",
    "# true_labels = []\n",
    "# probabilities = []\n",
    "# # iterate over the samples\n",
    "# for train_index, test_index in loo.split(features):\n",
    "#     # get the train and test data\n",
    "#     X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "#     # get the train and test labels\n",
    "#     y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "#     # fit the model\n",
    "#     clf.fit(X_train, y_train.values.ravel())\n",
    "#     # predict the test sample\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     # predict the probability\n",
    "#     y_prob = clf.predict_proba(X_test)\n",
    "#     # append the prediction\n",
    "#     predictions.append(y_pred)\n",
    "#     probabilities.append(y_prob)\n",
    "#     true_labels.append(y_test.values[0])\n",
    "# # convert the predictions to array\n",
    "# predictions = np.asarray(predictions)\n",
    "# true_labels = np.asarray(true_labels)\n",
    "# probabilities = np.asanyarray(probabilities).reshape(-1,2)[:,0]\n",
    "\n",
    "# # compute roc\n",
    "# roc_auc = roc_auc_score(true_labels, probabilities)\n",
    "\n",
    "# # # get metrics scores\n",
    "# # accuracy = accuracy_score(true_labels, predictions)\n",
    "# # precision = precision_score(true_labels, predictions)\n",
    "# # recall = recall_score(true_labels, predictions)\n",
    "# # f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "# # # print the scores all together\n",
    "# # print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}, \\nROC_AUC: {roc_auc}\\n')\n",
    "\n",
    "# # # display the confusion matrix\n",
    "# # cm = confusion_matrix(true_labels, predictions)\n",
    "# # ConfusionMatrixDisplay(cm).plot()\n",
    "# # plt.title('Confusion Matrix')\n",
    "\n",
    "# # plot the ROC curve\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(true_labels, probabilities)\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc})')\n",
    "# plt.plot([0,1],[0,1], 'k--')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# # get ideal threshold\n",
    "# optimal_idx = np.argmax(tpr - fpr)\n",
    "# optimal_threshold = thresholds[optimal_idx]\n",
    "# # plot the optimal threshold\n",
    "# plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='black', label='Best Threshold')\n",
    "# plt.legend()\n",
    "\n",
    "# # get optimal predictions\n",
    "# optimal_predictions = np.where(probabilities > optimal_threshold, 1, 0)\n",
    "# # get metrics scores\n",
    "# accuracy = accuracy_score(true_labels, optimal_predictions)\n",
    "# precision = precision_score(true_labels, optimal_predictions)\n",
    "# recall = recall_score(true_labels, optimal_predictions)\n",
    "# f1 = f1_score(true_labels, optimal_predictions)\n",
    "\n",
    "# # print the scores all together\n",
    "# print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}')\n",
    "# # display the confusion matrix\n",
    "# cm = confusion_matrix(true_labels, optimal_predictions)\n",
    "# ConfusionMatrixDisplay(cm).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Version: OO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictor class\n",
    "class predictor_machine():\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.clf = None\n",
    "        self.cv = LeaveOneOut()\n",
    "        self.features = None\n",
    "        self.num_samples = 0\n",
    "        self.labels = None\n",
    "        # lists\n",
    "        self.probabilities = []\n",
    "        self.true_labels = []\n",
    "        self.best_params = []\n",
    "\n",
    "    def scale_features(self, features:pd.DataFrame):\n",
    "        \"\"\"with the defined scaler, scale feature and return as a dataframe\n",
    "\n",
    "        Args:\n",
    "            features (pd.DataFrame): input features, in order of prediction. Only numerical values.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: scaled features\n",
    "        \"\"\"\n",
    "        self.scaler.fit(features)\n",
    "        features = pd.DataFrame(self.scaler.transform(features))\n",
    "        self.num_samples = len(features)\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "    def prepare_labels(self, labels:list, show_distribution:bool=False):\n",
    "        # labels to df\n",
    "        labels = pd.DataFrame(labels, columns=['label'])\n",
    "        if show_distribution:\n",
    "            print(f'The positive cases represent {labels[\"label\"].mean().round(3)*100}%')\n",
    "        \n",
    "        self.labels = labels\n",
    "\n",
    "    def train(self):\n",
    "        for train_index, test_index in self.cv.split(self.features):\n",
    "            # get the train and test data\n",
    "            X_train, X_test = self.features.iloc[train_index], self.features.iloc[test_index]\n",
    "            # get the train and test labels\n",
    "            y_train, y_test = self.labels.iloc[train_index], self.labels.iloc[test_index]\n",
    "            # fit the model\n",
    "            self.clf.fit(X_train, y_train.values.ravel())\n",
    "            # save best params of this iteration\n",
    "            self.best_params.append(self.clf.best_params_)\n",
    "            # predict the probability\n",
    "            y_prob = self.clf.predict_proba(X_test)\n",
    "            # append the prediction\n",
    "            self.probabilities.append(y_prob)\n",
    "            self.true_labels.append(y_test.values[0])\n",
    "        # convert to arrays\n",
    "        self.true_labels = np.asarray(self.true_labels)\n",
    "        self.probabilities = np.asanyarray(self.probabilities).reshape(-1,2)[:,0]\n",
    "\n",
    "        print(f'Training finished!')\n",
    "\n",
    "    def compute_metrics(self, plot_roc:bool=False, plot_CM:bool=False):\n",
    "        \n",
    "        roc_auc = roc_auc_score(self.true_labels, self.probabilities)\n",
    "        fpr, tpr, thresholds = roc_curve(self.true_labels, self.probabilities)\n",
    "        # get ideal threshold\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        if plot_roc:\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc})')\n",
    "            plt.plot([0,1],[0,1], 'k--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('ROC Curve')\n",
    "            plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='black', label=f'Best Threshold: {optimal_threshold.round(3)}')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        # get optimal predictions\n",
    "        optimal_predictions = np.where(self.probabilities > optimal_threshold, 1, 0)\n",
    "        accuracy = accuracy_score(self.true_labels, optimal_predictions)\n",
    "        precision = precision_score(self.true_labels, optimal_predictions)\n",
    "        recall = recall_score(self.true_labels, optimal_predictions)\n",
    "        f1 = f1_score(self.true_labels, optimal_predictions)\n",
    "        print(f'AUC:{roc_auc}\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}')\n",
    "        if plot_CM:\n",
    "            cm = confusion_matrix(self.true_labels, optimal_predictions)\n",
    "            ConfusionMatrixDisplay(cm).plot()\n",
    "            plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive cases represent 81.8%\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/core/indexing.py:1618\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/core/generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3941\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3942\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3943\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3946\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3948\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3949\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/core/generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 3932\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3934\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/core/internals/managers.py:960\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_indices:\n\u001b[0;32m--> 960\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/core/indexers/utils.py:284\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[363], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m predictor\u001b[38;5;241m.\u001b[39mscale_features(features)\n\u001b[1;32m     18\u001b[0m predictor\u001b[38;5;241m.\u001b[39mprepare_labels(labels, show_distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m predictor\u001b[38;5;241m.\u001b[39mcompute_metrics(plot_roc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, plot_CM\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[319], line 43\u001b[0m, in \u001b[0;36mpredictor_machine.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39miloc[train_index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# get the train and test labels\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# fit the model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/core/indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1651\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/core/indexing.py:1621\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n\u001b[0;32m-> 1621\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# get the features, remove the first column (patient ID)\n",
    "features = pd.read_csv(repo_path / 'data/deep/features/features_1024/V_2_features.csv').iloc[:,1:]\n",
    "labels = dataset_INCan().labels_list(receptor='RE')\n",
    "\n",
    "# prepare for the machine\n",
    "predictor = predictor_machine()\n",
    "\n",
    "\n",
    "# grid search\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.01, 0.1, 1, 10], 'gamma':[0.01, 0.1, 1]}\n",
    "# define the classifier\n",
    "pred = SVC(probability=True)\n",
    "# define the grid search, the best model is selected based on the roc_auc score\n",
    "predictor.clf = GridSearchCV(pred, parameters, cv=3, scoring='roc_auc', verbose=0, n_jobs=6)\n",
    "\n",
    "\n",
    "predictor.scale_features(features)\n",
    "predictor.prepare_labels(labels, show_distribution=True)\n",
    "predictor.train()\n",
    "predictor.compute_metrics(plot_roc=True, plot_CM=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedm-deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
