{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add repo path to the system path\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "repo_path= Path.cwd().resolve()\n",
    "while '.gitignore' not in os.listdir(repo_path): # while not in the root of the repo\n",
    "    repo_path = repo_path.parent #go up one level\n",
    "sys.path.insert(0,str(repo_path)) if str(repo_path) not in sys.path else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataset_INCan, patient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# normalize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# simple SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# use leave one out cross validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "# confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data to have zero mean and unit variance (Standard Scaling).\n",
    "- We may try other normalization?\n",
    "- In practice SVM and most of the other algorithms work better if the features are normalized like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get X values\n",
    "# features = pd.read_csv(repo_path / 'data/deep/features/features_1024/V_1_features.csv')\n",
    "# # remove the first column\n",
    "# features = features.iloc[:,1:]\n",
    "# # get y values\n",
    "# labels = dataset_INCan().labels_list(receptor='RE')\n",
    "# # labels to df\n",
    "# labels = pd.DataFrame(labels, columns=['label'])\n",
    "# # print label distribution porcentage\n",
    "# print(labels['label'].value_counts(normalize=True).values[0].round(3))\n",
    "\n",
    "# # create the scaler\n",
    "# scaler = StandardScaler()\n",
    "# # fit the scaler\n",
    "# scaler.fit(features)\n",
    "# # transform the features\n",
    "# features = pd.DataFrame(scaler.transform(features))\n",
    "\n",
    "# # create the classifier\n",
    "# clf = SVC(kernel='linear', C=0.1, gamma=0.1, probability=True)\n",
    "# # create the cross validation\n",
    "# loo = LeaveOneOut()\n",
    "# # get the number of samples\n",
    "# n_samples = len(features)\n",
    "# # create the predictions list\n",
    "# predictions = []\n",
    "# true_labels = []\n",
    "# probabilities = []\n",
    "# # iterate over the samples\n",
    "# for train_index, test_index in loo.split(features):\n",
    "#     # get the train and test data\n",
    "#     X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "#     # get the train and test labels\n",
    "#     y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "#     # fit the model\n",
    "#     clf.fit(X_train, y_train.values.ravel())\n",
    "#     # predict the test sample\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     # predict the probability\n",
    "#     y_prob = clf.predict_proba(X_test)\n",
    "#     # append the prediction\n",
    "#     predictions.append(y_pred)\n",
    "#     probabilities.append(y_prob)\n",
    "#     true_labels.append(y_test.values[0])\n",
    "# # convert the predictions to array\n",
    "# predictions = np.asarray(predictions)\n",
    "# true_labels = np.asarray(true_labels)\n",
    "# probabilities = np.asanyarray(probabilities).reshape(-1,2)[:,0]\n",
    "\n",
    "# # compute roc\n",
    "# roc_auc = roc_auc_score(true_labels, probabilities)\n",
    "\n",
    "# # # get metrics scores\n",
    "# # accuracy = accuracy_score(true_labels, predictions)\n",
    "# # precision = precision_score(true_labels, predictions)\n",
    "# # recall = recall_score(true_labels, predictions)\n",
    "# # f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "# # # print the scores all together\n",
    "# # print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}, \\nROC_AUC: {roc_auc}\\n')\n",
    "\n",
    "# # # display the confusion matrix\n",
    "# # cm = confusion_matrix(true_labels, predictions)\n",
    "# # ConfusionMatrixDisplay(cm).plot()\n",
    "# # plt.title('Confusion Matrix')\n",
    "\n",
    "# # plot the ROC curve\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(true_labels, probabilities)\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc})')\n",
    "# plt.plot([0,1],[0,1], 'k--')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# # get ideal threshold\n",
    "# optimal_idx = np.argmax(tpr - fpr)\n",
    "# optimal_threshold = thresholds[optimal_idx]\n",
    "# # plot the optimal threshold\n",
    "# plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='black', label='Best Threshold')\n",
    "# plt.legend()\n",
    "\n",
    "# # get optimal predictions\n",
    "# optimal_predictions = np.where(probabilities > optimal_threshold, 1, 0)\n",
    "# # get metrics scores\n",
    "# accuracy = accuracy_score(true_labels, optimal_predictions)\n",
    "# precision = precision_score(true_labels, optimal_predictions)\n",
    "# recall = recall_score(true_labels, optimal_predictions)\n",
    "# f1 = f1_score(true_labels, optimal_predictions)\n",
    "\n",
    "# # print the scores all together\n",
    "# print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}')\n",
    "# # display the confusion matrix\n",
    "# cm = confusion_matrix(true_labels, optimal_predictions)\n",
    "# ConfusionMatrixDisplay(cm).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Version: OO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictor class\n",
    "class predictor_machine():\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.clf = None\n",
    "        self.cv = LeaveOneOut()\n",
    "        self.features = None\n",
    "        self.num_samples = 0\n",
    "        self.labels = None\n",
    "        # lists\n",
    "        self.probabilities = []\n",
    "        self.true_labels = []\n",
    "        self.best_params = []\n",
    "\n",
    "    def scale_features(self, features:pd.DataFrame):\n",
    "        \"\"\"with the defined scaler, scale feature and return as a dataframe\n",
    "\n",
    "        Args:\n",
    "            features (pd.DataFrame): input features, in order of prediction. Only numerical values.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: scaled features\n",
    "        \"\"\"\n",
    "        self.scaler.fit(features)\n",
    "        features = pd.DataFrame(self.scaler.transform(features))\n",
    "        self.num_samples = len(features)\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "    def prepare_labels(self, labels:list, show_distribution:bool=False):\n",
    "        # labels to df\n",
    "        labels = pd.DataFrame(labels, columns=['label'])\n",
    "        if show_distribution:\n",
    "            print(f'The positive cases represent {labels[\"label\"].mean().round(3)*100}%')\n",
    "        \n",
    "        self.labels = labels\n",
    "\n",
    "    def train(self):\n",
    "        for train_index, test_index in self.cv.split(self.features):\n",
    "            # get the train and test data\n",
    "            X_train, X_test = self.features.iloc[train_index], self.features.iloc[test_index]\n",
    "            # get the train and test labels\n",
    "            y_train, y_test = self.labels.iloc[train_index], self.labels.iloc[test_index]\n",
    "            # fit the model\n",
    "            self.clf.fit(X_train, y_train.values.ravel())\n",
    "            # save best params of this iteration\n",
    "            self.best_params.append(self.clf.best_params_)\n",
    "            # predict the probability\n",
    "            y_prob = self.clf.predict_proba(X_test)\n",
    "            # append the prediction\n",
    "            self.probabilities.append(y_prob)\n",
    "            self.true_labels.append(y_test.values[0])\n",
    "        # convert to arrays\n",
    "        self.true_labels = np.asarray(self.true_labels)\n",
    "        self.probabilities = np.asanyarray(self.probabilities).reshape(-1,2)[:,0]\n",
    "\n",
    "        print(f'Training finished!')\n",
    "\n",
    "    def compute_metrics(self, plot_roc:bool=False, plot_CM:bool=False):\n",
    "        \n",
    "        roc_auc = roc_auc_score(self.true_labels, self.probabilities)\n",
    "        fpr, tpr, thresholds = roc_curve(self.true_labels, self.probabilities)\n",
    "        # get ideal threshold\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        if plot_roc:\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc})')\n",
    "            plt.plot([0,1],[0,1], 'k--')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('ROC Curve')\n",
    "            plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='black', label=f'Best Threshold: {optimal_threshold.round(3)}')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        # get optimal predictions\n",
    "        optimal_predictions = np.where(self.probabilities > optimal_threshold, 1, 0)\n",
    "        accuracy = accuracy_score(self.true_labels, optimal_predictions)\n",
    "        precision = precision_score(self.true_labels, optimal_predictions)\n",
    "        recall = recall_score(self.true_labels, optimal_predictions)\n",
    "        f1 = f1_score(self.true_labels, optimal_predictions)\n",
    "        print(f'AUC:{roc_auc}\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}')\n",
    "        if plot_CM:\n",
    "            cm = confusion_matrix(self.true_labels, optimal_predictions)\n",
    "            ConfusionMatrixDisplay(cm).plot()\n",
    "            plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ricardo/projects/Added_value_feature_uncertainty/data/deep/features/features_1024/V_2_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[361], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get the features, remove the first column (patient ID)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/deep/features/features_1024/V_2_features.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m dataset_INCan()\u001b[38;5;241m.\u001b[39mlabels_list(receptor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# prepare for the machine\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/cedm-deep/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ricardo/projects/Added_value_feature_uncertainty/data/deep/features/features_1024/V_2_features.csv'"
     ]
    }
   ],
   "source": [
    "# get the features, remove the first column (patient ID)\n",
    "features = pd.read_csv(repo_path / 'data/deep/features/features_1024/V_2_features.csv').iloc[:,1:]\n",
    "labels = dataset_INCan().labels_list(receptor='RE')\n",
    "\n",
    "# prepare for the machine\n",
    "predictor = predictor_machine()\n",
    "\n",
    "\n",
    "# grid search\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.01, 0.1, 1, 10], 'gamma':[0.01, 0.1, 1]}\n",
    "# define the classifier\n",
    "pred = SVC(probability=True)\n",
    "# define the grid search, the best model is selected based on the roc_auc score\n",
    "predictor.clf = GridSearchCV(pred, parameters, cv=3, scoring='roc_auc', verbose=0, n_jobs=6)\n",
    "\n",
    "\n",
    "predictor.scale_features(features)\n",
    "predictor.prepare_labels(labels, show_distribution=True)\n",
    "predictor.train()\n",
    "predictor.compute_metrics(plot_roc=True, plot_CM=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cedm-deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
